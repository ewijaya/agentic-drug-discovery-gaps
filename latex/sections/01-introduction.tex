\section{Introduction: The Promise vs Reality of Agentic AI in Drug Discovery}
\label{sec:introduction}

\subsection{The Current Narrative}

The past three years have witnessed an explosion of agentic AI systems targeting drug discovery workflows. In late 2023, Coscientist demonstrated autonomous chemical synthesis planning and execution \citep{boiko2023coscientist}, while ChemCrow showed how GPT-4 could orchestrate 18 chemistry tools for synthesis route optimization and safety assessment \citep{bran2023chemcrow}. More recently, ChatInvent completed a 13-month deployment at AstraZeneca, performing literature synthesis and hypothesis generation at scale \citep{he2026chatinvent}. PharmAgents extended this paradigm to integrate knowledge graphs with large language model reasoning for target identification and compound prioritization \citep{swanson2024pharmagents}, while systems like MADD and DiscoVerse promise multi-agent collaboration for end-to-end drug design.

These demonstrations have catalyzed excitement across the pharmaceutical industry. The dominant narrative positions agentic AI as the next frontier in computational drug discovery, moving beyond static prediction models to systems that can autonomously navigate literature, design experiments, and propose hypotheses. Industry editorials proclaim an "agentic era" where AI systems will act as collaborators rather than tools \citep{lakhan2025agentic}. Comprehensive technical surveys map an expanding landscape of agent architectures, tool integrations, and capability benchmarks \citep{seal2025aiagents}.

The architectural pattern underlying most current systems is remarkably consistent: a large language model serves as the central orchestrator, decomposing complex queries into tool calls, synthesizing results, and generating natural language explanations. ChemCrow's GPT-4 backbone routes requests to RDKit for molecular property calculation, PubChem for database searches, and specialized APIs for reaction prediction. ChatInvent mines scientific literature to identify research gaps and suggest experimental directions. Coscientist interfaces with laboratory automation platforms to translate synthesis plans into executable protocols.

This LLM-centric design has proven effective for tasks that map naturally to text-based reasoning: literature review, synthesis route enumeration, protocol documentation, and safety datasheet analysis. The systems excel when the knowledge required exists in their training corpora or can be retrieved through search, and when the outputs are text or simple API calls to well-defined computational tools.

\subsection{The Gap: What Happens Outside the Lab Automation Paradigm}

However, a closer examination of these systems reveals systematic blind spots. Current agentic AI architectures are optimized for a specific context: small-molecule drug discovery, target-based screening workflows, high-throughput in vitro assays, and well-resourced pharmaceutical companies with extensive computational infrastructure and large datasets. When applied outside this design envelope, to peptide therapeutics, in vivo efficacy modeling, or resource-constrained small biotechs, the limitations become stark.

Consider the problem of therapeutic peptide design for regenerative medicine. Unlike small molecules represented as SMILES strings with well-defined chemical properties, peptides are sequences of 5 to 50 amino acids with complex conformational dynamics, aggregation propensities, protease vulnerabilities, and immunogenic epitopes. The structure-activity relationships that govern peptide bioactivity do not transfer from small-molecule experience. Stability optimization requires modeling peptide-enzyme interactions across dozens of protease families. Receptor binding prediction demands protein language models like ESM-2 \citep{lin2023esm2} or ProtBERT \citep{elnaggar2021protbert}, not molecular fingerprints. Yet no current agent architecture provides native support for protein language model fine-tuning, conformational sampling, or aggregation prediction.

The disconnect becomes more pronounced when moving from in vitro screens to in vivo efficacy studies. Animal models generate longitudinal data across multiple modalities: behavioral scores tracked over weeks, tissue histology captured through imaging, transcriptomic responses measured via RNA sequencing, and clinical observations recorded in semi-structured notes. In a traumatic brain injury model, efficacy might manifest as improved motor coordination at day 7, reduced neuroinflammation at day 14, and enhanced neurogenesis at day 28, all correlated with behavioral phenotypes quantified through computer vision analysis of animal movement patterns. No existing agent system can integrate these heterogeneous, temporal data streams to predict long-term therapeutic outcomes or identify mechanistic signatures.

The assumption of abundant computational resources and large datasets further limits applicability. ChatInvent's deployment at AstraZeneca presumes access to institutional literature subscriptions, high-performance computing clusters, and proprietary compound libraries numbering in the millions. A small biotech developing peptide therapeutics might have 50 to 500 proprietary sequences tested across a handful of assays, a single GPU workstation, and a team where the same person designs experiments, runs machine learning models, and analyzes results. Transfer learning, few-shot adaptation, and batch-mode automation become essential rather than optional, yet current agent architectures provide no systematic support for these capabilities.

Perhaps most fundamentally, real drug discovery requires navigating multi-objective trade-offs under uncertainty. A candidate peptide might show tenfold higher bioactivity than alternatives but with a narrower safety margin, increased aggregation propensity, or reduced proteolytic stability. The optimal choice depends on the development stage, risk tolerance, and specific therapeutic context. Current agents optimize single metrics or treat multi-objective problems as weighted sums, ignoring the Pareto frontier structure of real design spaces and providing no support for uncertainty quantification or sensitivity analysis.

The gap between capability demonstrations and practitioner reality creates a fundamental question: how must agent architectures evolve to address therapeutic modalities beyond small molecules, data contexts beyond high-throughput screening, computational paradigms beyond LLM tool-calling, resource constraints beyond large pharma budgets, and decision frameworks beyond single-objective optimization? This paper draws on experience leading 14+ AI-driven projects spanning machine learning for multi-endpoint bioactivity prediction, generative peptide design with protein language models, reinforcement learning for sequence optimization, longitudinal in vivo efficacy modeling, behavioral phenotyping through computer vision, RNA sequencing analysis, and multi-objective safety versus efficacy navigation. Each project revealed architectural assumptions in current agent systems that do not generalize. Understanding these gaps is essential for building the next generation of computational partners in drug discovery.

The following sections identify five critical blind spots: the small molecule bias in tool design and model integration (\S\ref{sec:small-molecule}), the absence of in vivo to in silico bridges (\S\ref{sec:invivo}), the limitations of LLM-centric multi-agent orchestration (\S\ref{sec:multiparadigm}), the mismatch with small biotech realities (\S\ref{sec:smallbiotech}), and the single-metric optimization trap (\S\ref{sec:multiobjective}). We conclude with a practitioner's wishlist (\S\ref{sec:wishlist}) proposing concrete design principles for agent systems that can serve as true computational partners rather than sophisticated chatbots.
