\section{Gap 5: Multi-Objective Navigation}
\label{sec:multiobjective}

Drug discovery is fundamentally a multi-objective optimization problem. A therapeutic candidate must simultaneously satisfy constraints on bioactivity, selectivity, safety, stability, manufacturability, and cost. These objectives often conflict: modifications that improve potency may reduce selectivity; structural changes that enhance stability might increase immunogenicity; synthesis routes that yield high purity may be prohibitively expensive. Navigating these trade-offs requires understanding the Pareto frontier, the set of candidates where improving one objective necessarily degrades another, and making informed decisions based on risk tolerance, development stage, and therapeutic context.

Current agentic AI systems, however, are architected around single-objective optimization. ChemCrow optimizes for binding affinity or synthetic accessibility \citep{bran2023chemcrow}. Coscientist targets synthesis yield \citep{boiko2023coscientist}. When multiple objectives are considered, they are typically collapsed into a scalar via weighted sums: "Maximize 0.6 times bioactivity plus 0.4 times drug-likeness." This reduction discards critical information. The practitioner does not learn which candidates lie on the Pareto frontier, how sensitive rankings are to weight choices, or what trade-offs are required to improve a particular objective. The agent presents a single "optimal" solution, obscuring the decision space.

\subsection{The Single-Metric Trap}

The single-metric optimization paradigm reflects the machine learning training objective: minimize a loss function, maximize an accuracy metric. This framing is appropriate when the goal is well-defined and unidimensional. But drug discovery goals are multidimensional and context-dependent. What constitutes an optimal candidate depends on the indication, development stage, competitive landscape, and organizational risk tolerance. No scalar objective function can capture this complexity.

Consider peptide stability optimization. A peptide that degrades rapidly in serum has no therapeutic value, regardless of its in vitro bioactivity. Practitioners modify sequences to resist protease cleavage: substituting D-amino acids, incorporating non-natural amino acids, or cyclizing the peptide backbone. Each modification can improve stability but may reduce target affinity, increase aggregation propensity, or complicate synthesis. The optimal peptide balances these trade-offs, and the balance point depends on the route of administration (intravenous delivery tolerates lower stability than oral), the therapeutic window (narrow margins demand higher safety, even at the cost of reduced efficacy), and the development timeline (fast-to-clinic programs may accept lower stability to accelerate trials).

In our experience developing peptides for in vivo applications, safety-efficacy trade-offs dominated candidate selection. One peptide showed tenfold higher bioactivity than alternatives in proliferation assays, but at doses required for in vivo efficacy, it triggered mild hepatotoxicity in animal models. Another peptide had half the bioactivity but a safety profile supporting higher dosing, ultimately achieving comparable in vivo efficacy with better tolerability. A third peptide offered intermediate bioactivity and safety but superior proteolytic stability, enabling less frequent dosing. Which candidate is "optimal" depends on factors no scalar objective function can encode: patient population, dosing regimen, and regulatory risk tolerance.

Current agents cannot represent or reason about these trade-offs. They might predict that Peptide A has higher bioactivity than Peptide B, but they cannot articulate the trade-off: "Peptide A is twice as potent but has a threefold narrower safety margin. Choose A if you can tightly control dosing; choose B for greater robustness." They cannot visualize the Pareto frontier showing all candidates where improving bioactivity requires accepting increased toxicity risk. They cannot perform sensitivity analysis: "How much does this ranking change if we weight safety twice as heavily as efficacy?"

\subsection{Pareto Frontiers and Constraint Satisfaction}

The appropriate framework for multi-objective drug discovery is Pareto optimization. A candidate is Pareto-optimal if no other candidate improves one objective without degrading at least one other. The set of Pareto-optimal candidates forms the Pareto frontier. In a two-objective space (e.g., bioactivity and toxicity), the frontier is a curve; in three or more dimensions, it is a surface or hypersurface. The practitioner's task is to navigate this frontier, selecting candidates based on context-specific priorities.

Visualizing the Pareto frontier provides immediate insight into the trade-off structure. A steep region of the frontier indicates that large sacrifices in one objective are required for modest gains in another; a flat region indicates that substantial improvements in one objective are possible with minimal cost to others. Clusters of candidates on the frontier suggest distinct design strategies: high-potency, narrow-margin peptides versus moderate-potency, wide-margin peptides. Gaps in the frontier reveal unexplored regions of design space that might yield superior trade-offs.

In practice, constructing the Pareto frontier requires multi-objective optimization algorithms. Evolutionary algorithms like NSGA-II maintain a population of candidates, iteratively selecting for non-dominated solutions. Multi-objective Bayesian optimization models the objective functions as Gaussian processes, selects the next candidate to evaluate via acquisition functions that balance exploration and Pareto-improvement, and updates the models with experimental results. These methods require tight integration between generative models (proposing new candidates), predictive models (estimating objective values), and optimization algorithms (selecting candidates based on predicted trade-offs). Current agent architectures support none of this.

Constraint satisfaction adds another layer of complexity. Beyond optimizing objectives, candidates must satisfy hard constraints: synthesizability, solubility, membrane permeability, absence of toxicophores. A candidate with exceptional bioactivity and safety is worthless if it cannot be synthesized at scale or does not reach its site of action. Constrained multi-objective optimization requires identifying the Pareto frontier within the feasible region, the subset of design space satisfying all constraints. This is more challenging than unconstrained optimization; the feasible region may be disjoint, the constraints may conflict, and the Pareto frontier may lie on the boundary of feasibility.

In peptide design, synthesis feasibility is often the binding constraint. A computationally designed sequence incorporating five non-natural amino acids might have excellent predicted properties, but if those amino acids are not commercially available or are prohibitively expensive, the design is not actionable. A peptide requiring regioselective cyclization at non-standard positions might be unfeasible with current solid-phase synthesis protocols. Practitioners must balance computational optimization with synthetic pragmatism, a trade-off that requires domain knowledge and cannot be automated.

\subsection{Incorporating Uncertainty and Risk}

Predictions come with uncertainty. A bioactivity prediction of IC50 equals 10 nanomolar might have a 95% confidence interval of 5 to 20 nanomolar, or it might span 1 to 100 nanomolar, depending on model quality and training data coverage. Ignoring this uncertainty leads to poor decisions: selecting candidates with high predicted activity but wide uncertainty intervals, only to discover in validation that the predictions were optimistic. Incorporating uncertainty into multi-objective decision-making is essential but absent from current systems.

Bayesian optimization naturally handles uncertainty through Gaussian process models that provide predictive means and variances. Acquisition functions like expected improvement or upper confidence bound balance exploitation (selecting candidates with high predicted performance) and exploration (selecting candidates with high uncertainty, where validation provides maximum information gain). Over multiple rounds of design and testing, uncertainty decreases in explored regions and remains high in unexplored regions. The agent should visualize this uncertainty structure, enabling the practitioner to decide whether to focus on exploitation (synthesizing predicted best candidates) or exploration (probing uncertain regions to improve the model).

Risk profiles differ by development stage. In early discovery, practitioners tolerate high-risk, high-reward candidates: novel scaffolds with uncertain properties but potential for breakthrough performance. As candidates advance toward the clinic, risk tolerance decreases; late-stage candidates must have well-characterized properties and high confidence in efficacy and safety. Agents should adapt their recommendations to the project stage: suggesting diverse, high-uncertainty candidates early and converging on Pareto-optimal, well-characterized candidates late.

In our experience managing peptide development pipelines, this risk-stage coupling was explicit. Initial rounds prioritized diversity: sampling across sequence space to build a training set covering different structural motifs. Middle rounds balanced exploration and exploitation: synthesizing high-predicted-activity peptides while also probing regions of high model uncertainty. Final rounds focused on exploitation and de-risking: selecting candidates with robust predicted properties, narrow confidence intervals, and validated mechanisms of action. This progression required dynamic acquisition functions and explicit risk management, neither of which current agents support.

Sensitivity analysis is another missing capability. Given a set of Pareto-optimal candidates, how robust are their rankings to model uncertainty? If bioactivity predictions have 20% error, does Candidate A still dominate Candidate B? If safety predictions are biased optimistic (as they often are when training data lacks toxicity examples), which candidates remain on the Pareto frontier after correcting for this bias? Sensitivity analysis quantifies decision robustness, enabling practitioners to invest resources in candidates whose superiority is robust rather than contingent on optimistic model assumptions.

Multi-objective navigation is not a peripheral feature; it is the essence of drug discovery decision-making. Practitioners spend more time balancing trade-offs than optimizing single metrics. Agents that cannot represent Pareto frontiers, quantify uncertainty, or support risk-aware decision-making miss the core challenge. The goal is not to automate decisions but to structure the decision space: presenting the Pareto frontier with confidence intervals, performing sensitivity analysis to identify robust candidates, and enabling interactive exploration of trade-offs. Until agents embrace this framework, their recommendations will remain oversimplified and of limited practical value.
