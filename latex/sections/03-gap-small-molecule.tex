\subsection{Gap 1: Small-Molecule Representation Bias}
\label{sec:small-molecule}

Current agentic systems are architected around small molecules: SMILES strings, docking scores, synthetic accessibility metrics, and retrosynthesis planning. This works for medicinal chemistry but breaks down for peptide therapeutics requiring fundamentally different computational approaches.

\subsubsection{Findings}

All six frameworks evaluated assume small-molecule representations (SMILES strings, molecular fingerprints, docking scores). Task classes 2, 3, 5, 6, and 7 (peptide-specific workflows) receive zero coverage across all frameworks. No framework supports protein language models (ProtBERT, ESM-2, ProGen) as first-class components for sequence-based therapeutics design.

\subsubsection{Stranded Knowledge: A Diagnostic Experiment}

As a diagnostic, we probed four frontier LLMs on matched pharmaceutical knowledge
questions to test whether the small-molecule bias extends to the foundation models
powering these agents (\S\ref{sec:knowledge-probing}). All four models demonstrate
competent peptide reasoning across all five categories
(Table~\ref{tab:knowledge-probing-categories}, \cref{fig:knowledge-probing}). Across
200 paired observations, peptide questions receive marginally higher scores than
small-molecule questions (aggregate gap = $-0.115$, 95\% CI: $[-0.255, 0.02]$). No
model shows a statistically significant peptide deficit (all $p > 0.6$,
Bonferroni-adjusted $p = 1.0$), and the Friedman consistency test confirms this holds
uniformly across all four models ($\chi^2 = 0.454$, $p = 0.929$). Four of five
categories favor peptides; Optimization Approaches shows the largest pro-peptide gap
($+0.225$).

Expert validation revealed that models produce directionally correct but quantitatively
overconfident reasoning in both domains equally, consistent with a depth limitation
rather than a modality-specific knowledge gap. The paired within-model comparisons
driving the statistical tests are robust to calibration differences between expert and
automated scoring (see \S\ref{sec:discussion-limitations} for details).

The diagnostic isolates the defect: the peptide expertise is present in foundation
models but stranded behind small-molecule-only agent architectures. LLMs reason
competently about peptide SAR, ADMET properties, generative design, optimization, and
assay interpretation. The knowledge exists; no current agent provides a pathway to
surface it through peptide-aware tools, protein language model integration, or
sequence-native workflows. This strengthens rather than undermines \gap{1}: the fix
requires building the integration pipeline, not retraining the models.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig-llm-knowledge-probing.pdf}
\caption{Stranded Knowledge: LLM Peptide Competence vs Agent Capability. Mean scores
(0--3 scale) for four frontier LLMs across 50 matched question pairs spanning five
pharmaceutical knowledge categories. Blue bars: small-molecule questions; orange bars:
peptide questions. Error bars: 95\% bootstrap confidence intervals. All four models
demonstrate competent peptide reasoning at or above small-molecule levels (aggregate gap
= $-0.115$, 95\% CI: $[-0.255, 0.02]$, all Bonferroni-adjusted $p = 1.0$). This
knowledge is stranded: no current agentic framework surfaces it through peptide-aware
tools.}
\label{fig:knowledge-probing}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Knowledge Probing: Per-Category Score Breakdown. Mean scores (standard
deviation) aggregated across four models. Gap = peptide minus small-molecule mean
(positive indicates peptide advantage). $p$-values from one-sided Wilcoxon signed-rank
tests ($H_1$: SM $>$ peptide). Four of five categories show a peptide advantage,
confirming that peptide expertise exists across all knowledge categories tested.}
\label{tab:knowledge-probing-categories}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Category} & \textbf{SM Mean (SD)} & \textbf{PEP Mean (SD)} & \textbf{Gap} & \textbf{$p$-value} \\
\midrule
SAR Reasoning & 2.60 (0.63) & 2.55 (0.55) & $-0.05$ & 0.370 \\
ADMET / PK Properties & 2.33 (0.66) & 2.45 (0.68) & $+0.13$ & 0.755 \\
Generative Design & 2.10 (0.71) & 2.25 (0.74) & $+0.15$ & 0.805 \\
Optimization Approaches & 2.28 (0.75) & 2.50 (0.60) & $+0.23$ & 0.938 \\
Assay Interpretation & 2.38 (0.74) & 2.50 (0.68) & $+0.13$ & 0.767 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{The Peptide-Specific Challenge Space}

Therapeutic peptides (2 to 50 amino acids) bridge small molecules and biologics. Unlike rigid small molecules, peptides are conformationally flexible, sampling diverse structural states. They achieve high selectivity through induced-fit binding but face aggregation, protease degradation, and permeability barriers. These challenges extend beyond peptides to biologics broadly: antibodies require CDR loop modeling, nanobodies need single-domain folding, and fusion proteins demand multi-domain interaction prediction. The small-molecule bias is a biologics-wide limitation.

Peptide discovery diverges from small-molecule workflows. Structure-activity relationships do not transfer; conservative substitutions can abolish activity while drastic changes improve potency. Stability dominates. In neurological injury indications, efficacy-stability trade-offs exceeded potency concerns. A bioactive peptide with minute-scale serum half-life has no therapeutic value. Protease resistance requires modeling interactions across dozens of enzyme families. Immunogenicity demands epitope scanning and MHC binding prediction. Aggregation depends on charge distribution and hydrophobic patterning.

Current agents provide no pathway for these requirements. ChemCrow includes RDKit, which does not handle peptide conformational sampling. PharmAgents focuses on small-molecule structure-based design workflows not designed for flexible peptide interactions. ChatInvent mines small-molecule synthesis routes and molecular design, irrelevant to peptide synthesis.

Practitioners encounter immediate friction. SMILES encoding of peptides is error-prone, risking loss of stereochemical and conformational information, particularly for non-natural amino acids. Standard molecular fingerprints (Morgan, MACCS) perform poorly on peptides, which lack equivalent standard representations. Rigid-molecule docking produces unreliable scores. Retrosynthesis metrics are meaningless. Even data storage becomes awkward: sequence variants, post-translational modifications, and assay metadata rarely fit small-molecule databases designed for single canonical structures.

\subsubsection{Protein Language Models vs Molecular Fingerprints}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig2-workflow-complexity.jpeg}
\caption{Workflow Complexity: Small Molecules vs Peptides. Top: Small molecule workflow follows a linear path from SMILES representation through RDKit property calculation to docking. Bottom: Peptide workflow branches into multiple parallel analysis streams including structural prediction, aggregation propensity, stability, immunogenicity, membrane permeability, and protease resistance, requiring integration of diverse computational tools and protein language models.}
\label{fig:workflow-complexity}
\end{figure}

Protein language models define peptide design. ProtBERT \citep{elnaggar2022protbert}, ESM-2 \citep{lin2023esm2}, and ProGen \citep{madani2023progen} encode evolutionary and structural priors from millions of protein sequences. ESM-2 embeddings predict receptor types from sequence alone. ProtBERT fine-tuning enables transfer learning from limited labeled data, often requiring only hundreds of examples for task-specific classifiers.

Peptide-aware models are emerging. PepTune \citep{peptune2024} uses a masked discrete diffusion model with Monte Carlo Tree Guidance for multi-objective peptide generation, optimizing across binding affinity, permeability, and stability simultaneously. PepMLM \citep{pepmlm2025} fine-tunes ESM-2 to design peptide binders conditioned on target protein sequences, with experimental validation on disease-relevant targets. These are real advances in peptide-specific modeling. However, they are standalone tools, not components of agentic workflows. No current system chains peptide generation with proprietary fine-tuning, active learning, iterative design-test cycles, or multi-endpoint optimization in closed loops. The gap is workflow integration, not individual capability.

Building peptide workflows requires capabilities current agents lack. Developing a receptor binding classifier involves curating training sets, extracting ESM-2 embeddings, training supervised classifiers, validating performance, and iterating hyperparameters. This is gradient-based ML, not API calls. The work also depends on small, noisy datasets where careful cross-validation and calibration matter more than single headline metrics. Exposing these uncertainties clearly is a prerequisite for biologists to prioritize synthesis and testing. Without that, the workflow reverts to manual triage and ad hoc heuristics.
No current system supports this autonomously. LLM orchestrators treat models as inference-only APIs (see \S\ref{sec:multiparadigm} for detailed analysis of this architectural limitation). Agents retrieve embeddings but cannot train task-specific classifiers on proprietary data.

Generative modeling extends this gap. ProtGPT2 \citep{ferruz2022protgpt2} fine-tunes on therapeutic sequences for de novo generation. Reinforcement learning optimizes multi-objective reward functions combining bioactivity and stability, requiring reward models, policy networks, gradients, and KL regularization. These ML workflows requiring end-to-end training control exceed current agent architectures.

The gap reflects a missing paradigm, not a missing tool. Protein language models are the foundation of peptide discovery, demanding first-class support for training and fine-tuning. Without this, agents cannot support the core workflows practitioners use to move from sequence space exploration to experimentally validated leads.

\subsubsection{Capability Requirements Implied by Gap}

A peptide-aware agent meeting this requirement would accept a FASTA file of 200 labeled sequences and return a classifier with per-class AUC-ROC and calibration curves, or accept a generative model specification and return novel sequences with predicted property distributions and diversity metrics.

Peptide-aware architectures require protein language models as core components, not external APIs. First, fine-tuning pipelines: dataset curation, train-validation-test splits, learning rate scheduling, early stopping, checkpointing. Effective frameworks would fine-tune ProtBERT on 200 sequences and return calibrated classifiers with uncertainty estimates.

Second, structural biology integration. AlphaFold \citep{jumper2021alphafold} structure prediction is central to peptide design. Flexible docking requires conformational sampling. Molecular dynamics provides stability and kinetics insights. These tools would need to integrate into multi-step workflows and feed back into sequence optimization, rather than remaining isolated analyses.

Third, multi-objective optimization. Peptide design balances bioactivity, stability, selectivity, and immunogenicity. We used curriculum learning for in vivo efficacy: initially rewarding bioactivity improvements, then progressively adding stability and toxicity constraints. This prevented local optima and maintained diversity. Current agents provide no framework for multi-stage optimization.

Fourth, diversity-aware generation. Generative models suffer mode collapse, producing reward-maximizing sequences with little variety. Practitioners use diversity penalties and max-min rewards, requiring state maintenance and dynamic sampling. LLM agents treat tool calls as stateless.

Finally, active learning loops. Limited budgets require careful peptide selection via acquisition functions that prioritize uncertain predictions across multiple rounds (see \S\ref{sec:smallbiotech}).

Peptide discovery is a distinct paradigm requiring ML training, structural biology, and multi-objective optimization as core capabilities. It also requires sequence-aware data management: tracking modifications, synthesis constraints, and assay provenance across iterative cycles. The small-molecule bias reflects architectural assumptions that limit current frameworks.
