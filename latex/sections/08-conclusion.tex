\section{Conclusion: From Assistants to True Partners}
\label{sec:conclusion}

The emergence of agentic AI in drug discovery represents a genuine inflection point. Systems like ChatInvent, Coscientist, and ChemCrow demonstrate that large language models can orchestrate domain-specific tools, navigate scientific literature, and generate actionable hypotheses. These capabilities, unimaginable five years ago, have catalyzed excitement across the pharmaceutical industry and inspired ambitious visions of autonomous research systems. But enthusiasm must be tempered with realism. Current agent architectures are optimized for a specific context: small-molecule drug discovery, target-based screening, high-throughput in vitro assays, and well-resourced pharmaceutical companies. When applied outside this design envelope, systematic blind spots emerge.

This paper has identified five critical gaps through the lens of practitioner experience across 14+ AI-driven drug discovery projects. The small-molecule bias limits applicability to peptides and biologics, which require protein language models, flexible docking, and biophysical property prediction fundamentally different from small-molecule cheminformatics. The absence of in vivo to in silico bridges leaves practitioners without support for the longitudinal, multi-modal data that defines therapeutic validation: behavioral phenotyping, tissue imaging, transcriptomics, and safety-efficacy trade-offs that cannot be predicted from in vitro assays alone. The LLM-centric orchestration paradigm excludes the computational paradigms that define modern drug discovery: machine learning training, reinforcement learning, simulation, and constrained optimization. The large-pharma resource assumptions ignore the realities of small biotechnology companies operating with 10 to 100 times less data, compute, and personnel. The single-metric optimization focus misses the multi-objective navigation at the heart of drug development: balancing bioactivity, safety, stability, and synthesizability under uncertainty.

These gaps are not isolated deficiencies. They reflect architectural assumptions that must be revisited if agent systems are to serve the breadth of drug discovery contexts. Addressing them requires five design principles: multi-paradigm orchestration that treats machine learning training and reinforcement learning as first-class primitives, modality-aware architectures with native support for peptides and biologics, in vivo to in silico integration through temporal modeling and causal inference, data-efficient learning via transfer learning and active learning, and multi-objective optimization with uncertainty quantification and Pareto frontier visualization.

The goal is not to build autonomous systems that replace human expertise. Drug discovery is too complex, too uncertain, and too context-dependent for full automation. The biological systems we seek to perturb are products of billions of years of evolution, shaped by selection pressures we often do not understand. Therapeutic candidates must navigate regulatory frameworks, manufacturing constraints, market dynamics, and patient heterogeneity that no computational model can fully capture. Human judgment, informed by domain knowledge, mechanistic intuition, and risk tolerance calibrated to organizational context, remains essential.

The vision, instead, is computational partners that augment practitioner capabilities. The agent handles repetitive workflows: data preprocessing, model training, hyperparameter tuning, result visualization. It flags anomalies, quantifies uncertainty, and structures decision spaces through Pareto frontiers and sensitivity analyses. It enables practitioners to explore design space more efficiently, test hypotheses more rigorously, and make decisions with better-calibrated confidence. The human focuses on the irreducible cognitive core: formulating biological hypotheses, interpreting results in mechanistic context, making strategic trade-offs, and designing experiments that test causal relationships.

This partnership requires bidirectional learning. Agents must learn from practitioner decisions: which trade-offs were prioritized, which mechanistic hypotheses proved correct, which models generalized beyond their training distributions. Practitioners must learn to trust agent recommendations calibrated by past accuracy and to distrust them when applied outside validated domains. The relationship is iterative: initial recommendations are tentative, refined through feedback and validation. Over time, the agent's internal models improve, and the practitioner's mental model of agent capabilities sharpens. This co-evolution is the hallmark of effective human-AI collaboration.

The measure of success is not benchmark metrics or automation percentages but impact on practitioner workflows. Does the agent reduce the time from hypothesis to validated lead? Does it surface candidates that human intuition alone would miss? Does it enable better-informed decisions under uncertainty, reducing late-stage failures? Does it scale to resource-constrained contexts where it is most needed? If next-generation systems embody the principles proposed here, the answers can be yes. If they remain LLM-centric chatbots optimized for large pharma contexts, they risk becoming impressive demonstrations that never achieve broad utility.

\subsection{A Call to Action}

Realizing this vision requires concerted effort across research communities, practitioner organizations, and funding agencies.

\textbf{For researchers building agent systems:} Move beyond LLM tool-calling to multi-paradigm orchestration. Integrate machine learning training, reinforcement learning, and simulation as first-class capabilities. Design for data efficiency: few-shot learning, transfer learning, and active learning must be core features, not afterthoughts. Support modalities beyond small molecules: peptides, proteins, antibodies, and nucleic acids. Embrace multi-objective optimization with uncertainty quantification and Pareto visualization. Build batch-mode workflows for practitioners managing multiple projects, not interactive chatbots requiring constant supervision.

\textbf{For practitioners in drug discovery:} Share anonymized problem formulations and dataset characteristics to guide agent development. Collaborate on open-source tools and benchmarks reflecting real-world complexity, not sanitized toy problems. Demand systems that respect resource constraints, quantify uncertainty, and support human-in-the-loop decision-making. Provide feedback on agent recommendations: which succeeded, which failed, and why. This feedback loop is essential for systems to improve beyond their initial deployment.

\textbf{For funding agencies and pharmaceutical organizations:} Support research at the intersection of AI agents and biological complexity. Fund open-source infrastructure: API standards for protein language models and structural biology tools, version-controlled datasets for reproducibility, and workflow orchestration systems for bioinformatics. Prioritize translational impact over benchmark performance. Encourage collaborations between large pharmaceutical companies with data and infrastructure and small biotechs where resource constraints drive innovation in data efficiency and workflow automation.

The past three years have demonstrated what is possible when large language models are adapted to drug discovery. The next three years will determine whether that promise generalizes beyond initial demonstrations to transform how therapeutic candidates are designed, optimized, and validated across the diversity of contexts where innovation happens. The gaps identified here are not insurmountable. They are engineering challenges requiring thoughtful design, cross-disciplinary collaboration, and sustained effort. If the field rises to meet them, agentic AI can become a transformative tool in the fight against disease. If not, it will remain a curiosity, impressive in controlled settings but of limited practical value. The choice is ours.
